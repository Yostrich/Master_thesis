Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job stats:
job                                   count    min threads    max threads
----------------------------------  -------  -------------  -------------
NegPeaksToBedFile                         1              1              1
addTotalReadsToCounts                     2              1              1
all                                       1              1              1
clusterReads                              2              1              1
combineCovAndPeaks                        2              1              1
createGenomecov                           2              1              1
extractSequences                          2              1              1
getAllOverlappingPeaks                    1              1              1
getInformationFromOverlappingPeaks        1              1              1
getOverlappingPeaksWithError              4              1              1
getPeaks                                  1              1              1
splitOverlappingPeaks                     1              1              1
termseqPeakCalling                        2              1              1
total                                    22              1              1

Select jobs to execute...

[Fri Oct 14 09:25:19 2022]
rule createGenomecov:
    input: BAM_files_LUZ7/LUZ7_enriched_t5.sorted.bam
    output: LUZ7_peak_calling/LUZ7_enriched_t5.5end.minus.bedgraph
    jobid: 40
    reason: Missing output files: LUZ7_peak_calling/LUZ7_enriched_t5.5end.minus.bedgraph
    wildcards: phage=LUZ7, prefix=LUZ7_enriched_t5, num=5, sign=minus
    resources: tmpdir=/tmp

[Fri Oct 14 09:25:25 2022]
Finished job 40.
1 of 22 steps (5%) done
Select jobs to execute...

[Fri Oct 14 09:25:25 2022]
rule termseqPeakCalling:
    input: LUZ7_peak_calling/LUZ7_enriched_t5.5end.minus.bedgraph
    output: LUZ7_peak_calling/LUZ7_enriched_t5.5end.minus.peaks
    jobid: 39
    reason: Missing output files: LUZ7_peak_calling/LUZ7_enriched_t5.5end.minus.peaks; Input files updated by another job: LUZ7_peak_calling/LUZ7_enriched_t5.5end.minus.bedgraph
    wildcards: phage=LUZ7, prefix=LUZ7_enriched_t5, num=5, sign=minus
    resources: tmpdir=/tmp

[Fri Oct 14 09:25:33 2022]
Finished job 39.
2 of 22 steps (9%) done
Select jobs to execute...

[Fri Oct 14 09:25:33 2022]
rule extractSequences:
    input: TSS_LUZ7_t5/LUZ7_enriched_t5_peaks.plus.bed
    output: TSS_LUZ7_t5/LUZ7_enriched_t5_TSS_seq.plus.fa.out
    jobid: 1
    reason: Missing output files: TSS_LUZ7_t5/LUZ7_enriched_t5_TSS_seq.plus.fa.out
    wildcards: phage=LUZ7, ident=t5, cond=enriched, sign=plus
    resources: tmpdir=/tmp

[Fri Oct 14 09:25:33 2022]
Error in rule extractSequences:
    jobid: 1
    output: TSS_LUZ7_t5/LUZ7_enriched_t5_TSS_seq.plus.fa.out
    shell:
        
        bedtools getfasta -fi LUZ7.fasta -bed TSS_LUZ7_t5/LUZ7_enriched_t5_peaks.plus.bed -fo TSS_LUZ7_t5/LUZ7_enriched_t5_TSS_seq.plus.fa.out -s -name 
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job extractSequences since they might be corrupted:
TSS_LUZ7_t5/LUZ7_enriched_t5_TSS_seq.plus.fa.out
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2022-10-14T092516.112492.snakemake.log
