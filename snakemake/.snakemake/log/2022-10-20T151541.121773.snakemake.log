Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job stats:
job                    count    min threads    max threads
-------------------  -------  -------------  -------------
PosPeaksToBedFile          1              1              1
createNotebook             1              1              1
extractSequencesTSS        1              1              1
total                      3              1              1

Select jobs to execute...

[Thu Oct 20 15:15:41 2022]
rule PosPeaksToBedFile:
    input: TSS_LUZ7_t20/enr_ratios_LUZ7_t20.plus.csv
    output: TSS_LUZ7_t20/LUZ7_enriched_t20_peaks.plus.bed, TSS_LUZ7_t20/LUZ7_control_t20_peaks.plus.bed
    jobid: 2
    reason: Missing output files: TSS_LUZ7_t20/LUZ7_enriched_t20_peaks.plus.bed; Params have changed since last execution
    wildcards: phage=LUZ7, ident=t20
    resources: tmpdir=/tmp

[Thu Oct 20 15:15:41 2022]
Finished job 2.
1 of 3 steps (33%) done
Removing temporary output TSS_LUZ7_t20/LUZ7_control_t20_peaks.plus.bed.
Select jobs to execute...

[Thu Oct 20 15:15:41 2022]
rule extractSequencesTSS:
    input: TSS_LUZ7_t20/LUZ7_enriched_t20_peaks.plus.bed
    output: TSS_LUZ7_t20/TSS_seq_LUZ7_enriched_t20.plus.fa.out
    jobid: 1
    reason: Input files updated by another job: TSS_LUZ7_t20/LUZ7_enriched_t20_peaks.plus.bed
    wildcards: phage=LUZ7, ident=t20, cond=enriched, sign=plus
    resources: tmpdir=/tmp

[Thu Oct 20 15:15:41 2022]
Finished job 1.
2 of 3 steps (67%) done
Removing temporary output TSS_LUZ7_t20/LUZ7_enriched_t20_peaks.plus.bed.
Select jobs to execute...

[Thu Oct 20 15:15:41 2022]
rule createNotebook:
    input: TSS_LUZ7_t20/TSS_seq_LUZ7_enriched_t20.plus.fa.out
    output: TSS_LUZ7_t20/structural_properties/LUZ7_t20_curvature.plus.png, TSS_LUZ7_t20/structural_properties/LUZ7_t20_curvature.plus.csv, TSS_LUZ7_t20/structural_properties/LUZ7_t20_stability.plus.png, TSS_LUZ7_t20/structural_properties/LUZ7_t20_stability.plus.csv
    log: logs/notebooks/LUZ7_t20.plus.ipynb
    jobid: 0
    reason: Input files updated by another job: TSS_LUZ7_t20/TSS_seq_LUZ7_enriched_t20.plus.fa.out
    wildcards: phage=LUZ7, ident=t20, sign=plus
    resources: tmpdir=/tmp

[Thu Oct 20 15:15:48 2022]
Error in rule createNotebook:
    jobid: 0
    output: TSS_LUZ7_t20/structural_properties/LUZ7_t20_curvature.plus.png, TSS_LUZ7_t20/structural_properties/LUZ7_t20_curvature.plus.csv, TSS_LUZ7_t20/structural_properties/LUZ7_t20_stability.plus.png, TSS_LUZ7_t20/structural_properties/LUZ7_t20_stability.plus.csv
    log: logs/notebooks/LUZ7_t20.plus.ipynb (check log file(s) for error message)

RuleException:
CalledProcessErrorin line 11 of /mnt/c/Users/danis/Desktop/Thesis/pipeline_snakemake/workflow/rules/notebookStructuralProperties.smk:
Command 'set -euo pipefail;  jupyter-nbconvert --log-level ERROR --execute --output /mnt/c/Users/danis/Desktop/Thesis/pipeline_snakemake/logs/notebooks/LUZ7_t20.plus.ipynb --to notebook --ExecutePreprocessor.timeout=-1 /mnt/c/Users/danis/Desktop/Thesis/pipeline_snakemake/.snakemake/scripts/tmp2cuq76rl.structuralProperties.py.ipynb' returned non-zero exit status 1.
  File "/mnt/c/Users/danis/Desktop/Thesis/pipeline_snakemake/workflow/rules/notebookStructuralProperties.smk", line 11, in __rule_createNotebook
  File "/home/yostrich/anaconda3/envs/snakemake/lib/python3.10/concurrent/futures/thread.py", line 58, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2022-10-20T151541.121773.snakemake.log
