Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job stats:
job                  count    min threads    max threads
-----------------  -------  -------------  -------------
PosPeaksToBedFile        1              1              1
all                      1              1              1
total                    2              1              1

Select jobs to execute...

[Wed Oct 12 16:14:33 2022]
rule PosPeaksToBedFile:
    input: TSS_LUZ7_t5/enrRatios_LUZ7_t5.plus.csv
    output: TSS_LUZ7_t5/LUZ7_enriched_t5_peaks.plus.bed, TSS_LUZ7_t5/LUZ7_control_t5_peaks.plus.bed
    jobid: 1
    reason: Missing output files: TSS_LUZ7_t5/LUZ7_enriched_t5_peaks.plus.bed
    wildcards: phage=LUZ7, ident=t5
    resources: tmpdir=/tmp

RuleException in rule PosPeaksToBedFile in line 64 of /mnt/c/Users/danis/Desktop/Thesis/pipeline_snakemake/workflow/rules/annotateTSS.smk:
IndexError: list index out of range, when formatting the following:

        awk -v FS='	' -v OFS='	' -F ' ' '{{print $1, $4 - {params.up}, $4 + {params.down}, "TSS_" NR, "+"}}' {input[0]} | uniq > {output[0]}
        awk -v FS='	' -v OFS='	' -F ' ' '{{print $8, $11 - {params.up}, $11 + {params.down}, "TSS_" NR, "+"}}' {input[1]} | uniq > {output[1]}
        sed -i 's/"//g' {output[0]}
        sed -i 's/"//g' {output[1]}
        
